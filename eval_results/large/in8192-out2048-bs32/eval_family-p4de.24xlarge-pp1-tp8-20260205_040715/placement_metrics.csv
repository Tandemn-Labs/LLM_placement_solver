model_name,max_input_length,max_output_length,batch_size,total_tokens_per_sec,input_tokens_per_sec,output_tokens_per_sec,cost_per_hour,dollar_per_million_token,total_runtime_hours,total_cost,pipeline_stages,device_type,pp,mem_per_gpu_gb,placement,layer_mapping,tp_per_stage,num_gpus,total_layers,status
llama3-70b,8192,2048,32,930.65,744.52,186.13,40.96,12.225687,0.30,12.23,1,p4de.24xlarge#0,1,{PP_1:80.0},{PP_1:{p4de.24xlarge#0:8}},{PP_1:1-80},{PP_1:8},8,80,SUCCESS
