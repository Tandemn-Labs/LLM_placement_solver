{
  "config": {
    "model_name": "llama3-70b",
    "num_decoder_layers": 80,
    "sequence_length": 2048,
    "output_length": 512,
    "min_batch_size": 32,
    "max_batch_size": 32,
    "optimal_batch_size": 32,
    "d_model": 8192,
    "d_hidden": 28672,
    "max_pipeline_stages": 8,
    "min_memory_utilization": 0.1
  },
  "solution": {
    "objective_value": 0.0,
    "batch_size": 32,
    "throughput_tokens_per_sec": 640.7101839570261,
    "raw_throughput_tokens_per_sec": 4152.751192314058,
    "pipeline_efficiency": 0.5142857142857142,
    "cost_per_hour": 54.8,
    "cost_per_token": 2.3758358464368054e-05,
    "total_runtime_hours": 0.4335466873059864,
    "meets_cost_threshold": true,
    "tp_configuration": {
      "g6e.24xlarge#0": 4,
      "g6e.24xlarge#1": 4,
      "g6e.24xlarge#2": 4,
      "g6e.24xlarge#3": 4
    },
    "gpu_assignments": [
      {
        "gpu_type": "g6e.24xlarge#0",
        "partition_id": 0,
        "gpu_ids": [
          0,
          1,
          2,
          3
        ],
        "global_gpu_ids": [
          72,
          73,
          74,
          75
        ],
        "tp_degree": 4,
        "start_layer": 1,
        "end_layer": 20,
        "segment_size": 20,
        "throughput": 4152.751192314058
      },
      {
        "gpu_type": "g6e.24xlarge#1",
        "partition_id": 1,
        "gpu_ids": [
          0,
          1,
          2,
          3
        ],
        "global_gpu_ids": [
          76,
          77,
          78,
          79
        ],
        "tp_degree": 4,
        "start_layer": 21,
        "end_layer": 40,
        "segment_size": 20,
        "throughput": 4152.751192314058
      },
      {
        "gpu_type": "g6e.24xlarge#2",
        "partition_id": 2,
        "gpu_ids": [
          0,
          1,
          2,
          3
        ],
        "global_gpu_ids": [
          80,
          81,
          82,
          83
        ],
        "tp_degree": 4,
        "start_layer": 41,
        "end_layer": 60,
        "segment_size": 20,
        "throughput": 4152.751192314058
      },
      {
        "gpu_type": "g6e.24xlarge#3",
        "partition_id": 3,
        "gpu_ids": [
          0,
          1,
          2,
          3
        ],
        "global_gpu_ids": [
          84,
          85,
          86,
          87
        ],
        "tp_degree": 4,
        "start_layer": 61,
        "end_layer": 80,
        "segment_size": 20,
        "throughput": 4152.751192314058
      }
    ],
    "network_connections": [
      {
        "from_segment": {
          "gpu_type": "g6e.24xlarge#0",
          "partition_id": 0,
          "start_layer": 1,
          "end_layer": 20
        },
        "to_segment": {
          "gpu_type": "g6e.24xlarge#1",
          "partition_id": 1,
          "start_layer": 21,
          "end_layer": 40
        },
        "throughput": 819200.0
      },
      {
        "from_segment": {
          "gpu_type": "g6e.24xlarge#1",
          "partition_id": 1,
          "start_layer": 21,
          "end_layer": 40
        },
        "to_segment": {
          "gpu_type": "g6e.24xlarge#2",
          "partition_id": 2,
          "start_layer": 41,
          "end_layer": 60
        },
        "throughput": 819200.0
      },
      {
        "from_segment": {
          "gpu_type": "g6e.24xlarge#2",
          "partition_id": 2,
          "start_layer": 41,
          "end_layer": 60
        },
        "to_segment": {
          "gpu_type": "g6e.24xlarge#3",
          "partition_id": 3,
          "start_layer": 61,
          "end_layer": 80
        },
        "throughput": 819200.0
      }
    ],
    "solve_status": null,
    "num_pipeline_stages": 4
  }
}