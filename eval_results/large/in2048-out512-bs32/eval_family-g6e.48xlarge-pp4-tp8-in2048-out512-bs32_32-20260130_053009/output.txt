2026-01-30 05:30:11,659 - INFO -   Instance p4de.24xlarge#0: 8×A100, 80GB, $40.96/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,659 - INFO -   Instance p3dn.24xlarge#0: 8×V100, 32GB, $31.21/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,659 - INFO -   Instance p3dn.24xlarge#1: 8×V100, 32GB, $31.21/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,659 - INFO -   Instance p3dn.24xlarge#2: 8×V100, 32GB, $31.21/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,659 - INFO -   Instance p3dn.24xlarge#3: 8×V100, 32GB, $31.21/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,659 - INFO -   Instance g6e.48xlarge#0: 8×L40S, 48GB, $27.39/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,659 - INFO -   Instance g6e.48xlarge#1: 8×L40S, 48GB, $27.39/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.48xlarge#2: 8×L40S, 48GB, $27.39/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.48xlarge#3: 8×L40S, 48GB, $27.39/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.24xlarge#0: 4×L40S, 48GB, $13.70/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.24xlarge#1: 4×L40S, 48GB, $13.70/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.24xlarge#2: 4×L40S, 48GB, $13.70/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.24xlarge#3: 4×L40S, 48GB, $13.70/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.12xlarge#0: 2×L40S, 48GB, $6.85/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.12xlarge#1: 2×L40S, 48GB, $6.85/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.12xlarge#2: 2×L40S, 48GB, $6.85/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.12xlarge#3: 2×L40S, 48GB, $6.85/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.4xlarge#0: 1×L40S, 48GB, $3.42/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.4xlarge#1: 1×L40S, 48GB, $3.42/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.4xlarge#2: 1×L40S, 48GB, $3.42/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,660 - INFO -   Instance g6e.4xlarge#3: 1×L40S, 48GB, $3.42/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.48xlarge#0: 8×A10, 24GB, $16.29/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.48xlarge#1: 8×A10, 24GB, $16.29/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.48xlarge#2: 8×A10, 24GB, $16.29/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.48xlarge#3: 8×A10, 24GB, $16.29/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.24xlarge#0: 4×A10, 24GB, $8.14/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.24xlarge#1: 4×A10, 24GB, $8.14/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.24xlarge#2: 4×A10, 24GB, $8.14/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.24xlarge#3: 4×A10, 24GB, $8.14/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.12xlarge#0: 4×A10, 24GB, $5.67/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.12xlarge#1: 4×A10, 24GB, $5.67/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.12xlarge#2: 4×A10, 24GB, $5.67/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.12xlarge#3: 4×A10, 24GB, $5.67/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.4xlarge#0: 1×A10, 24GB, $1.62/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.4xlarge#1: 1×A10, 24GB, $1.62/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.4xlarge#2: 1×A10, 24GB, $1.62/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,661 - INFO -   Instance g5.4xlarge#3: 1×A10, 24GB, $1.62/instance-hour (from cloud (AWS))
2026-01-30 05:30:11,674 - INFO - Loaded network bandwidth from /mnt/projects/LLM_placement_solver/config/network_bandwidth.csv
2026-01-30 05:30:11,675 - INFO - Optimization priority: cost_first (weight=0.90)
2026-01-30 05:30:11,675 - INFO - Workload phase: aggregated
2026-01-30 05:30:11,676 - INFO - GPU p4de.24xlarge#0: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU p3dn.24xlarge#0: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU p3dn.24xlarge#1: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU p3dn.24xlarge#2: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU p3dn.24xlarge#3: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.48xlarge#0: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.48xlarge#1: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.48xlarge#2: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.48xlarge#3: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.24xlarge#0: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.24xlarge#1: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.24xlarge#2: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.24xlarge#3: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.12xlarge#0: max_tp=2, generated 3 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.12xlarge#1: max_tp=2, generated 3 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.12xlarge#2: max_tp=2, generated 3 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.12xlarge#3: max_tp=2, generated 3 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.4xlarge#0: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.4xlarge#1: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,676 - INFO - GPU g6e.4xlarge#2: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g6e.4xlarge#3: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.48xlarge#0: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.48xlarge#1: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.48xlarge#2: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.48xlarge#3: max_tp=8, generated 15 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.24xlarge#0: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.24xlarge#1: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.24xlarge#2: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.24xlarge#3: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.12xlarge#0: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.12xlarge#1: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.12xlarge#2: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.12xlarge#3: max_tp=4, generated 7 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.4xlarge#0: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.4xlarge#1: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.4xlarge#2: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU g5.4xlarge#3: max_tp=1, generated 1 allocations with unique partition IDs
2026-01-30 05:30:11,677 - INFO - GPU p4de.24xlarge#0 with TP=8: max 80 layers
2026-01-30 05:30:11,677 - INFO - GPU p3dn.24xlarge#0 with TP=8: max 80 layers
2026-01-30 05:30:11,677 - INFO - GPU p3dn.24xlarge#1 with TP=8: max 80 layers
2026-01-30 05:30:11,677 - INFO - GPU p3dn.24xlarge#2 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU p3dn.24xlarge#3 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.48xlarge#0 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.48xlarge#1 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.48xlarge#2 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.48xlarge#3 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.24xlarge#0 with TP=4: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.24xlarge#1 with TP=4: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.24xlarge#2 with TP=4: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.24xlarge#3 with TP=4: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.12xlarge#0 with TP=2: max 43 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.12xlarge#1 with TP=2: max 43 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.12xlarge#2 with TP=2: max 43 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.12xlarge#3 with TP=2: max 43 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.4xlarge#0 with TP=1: max 20 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.4xlarge#1 with TP=1: max 20 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.4xlarge#2 with TP=1: max 20 layers
2026-01-30 05:30:11,678 - INFO - GPU g6e.4xlarge#3 with TP=1: max 20 layers
2026-01-30 05:30:11,678 - INFO - GPU g5.48xlarge#0 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g5.48xlarge#1 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g5.48xlarge#2 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g5.48xlarge#3 with TP=8: max 80 layers
2026-01-30 05:30:11,678 - INFO - GPU g5.24xlarge#0 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.24xlarge#1 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.24xlarge#2 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.24xlarge#3 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.12xlarge#0 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.12xlarge#1 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.12xlarge#2 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.12xlarge#3 with TP=4: max 43 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.4xlarge#0 with TP=1: max 8 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.4xlarge#1 with TP=1: max 8 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.4xlarge#2 with TP=1: max 8 layers
2026-01-30 05:30:11,679 - INFO - GPU g5.4xlarge#3 with TP=1: max 8 layers
2026-01-30 05:30:11,679 - INFO - GPU p4de.24xlarge#0 with TP=8: min 80 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU p3dn.24xlarge#0 with TP=8: min 58 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU p3dn.24xlarge#1 with TP=8: min 58 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU p3dn.24xlarge#2 with TP=8: min 58 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU p3dn.24xlarge#3 with TP=8: min 58 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU g6e.48xlarge#0 with TP=8: min 80 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU g6e.48xlarge#1 with TP=8: min 80 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU g6e.48xlarge#2 with TP=8: min 80 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU g6e.48xlarge#3 with TP=8: min 80 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU g6e.24xlarge#0 with TP=4: min 44 layers (for 50% utilization)
2026-01-30 05:30:11,679 - INFO - GPU g6e.24xlarge#1 with TP=4: min 44 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.24xlarge#2 with TP=4: min 44 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.24xlarge#3 with TP=4: min 44 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.12xlarge#0 with TP=2: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.12xlarge#1 with TP=2: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.12xlarge#2 with TP=2: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.12xlarge#3 with TP=2: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.4xlarge#0 with TP=1: min 9 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.4xlarge#1 with TP=1: min 9 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.4xlarge#2 with TP=1: min 9 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g6e.4xlarge#3 with TP=1: min 9 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.48xlarge#0 with TP=8: min 43 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.48xlarge#1 with TP=8: min 43 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.48xlarge#2 with TP=8: min 43 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.48xlarge#3 with TP=8: min 43 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.24xlarge#0 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.24xlarge#1 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.24xlarge#2 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.24xlarge#3 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.12xlarge#0 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.12xlarge#1 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.12xlarge#2 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,680 - INFO - GPU g5.12xlarge#3 with TP=4: min 21 layers (for 50% utilization)
2026-01-30 05:30:11,681 - INFO - GPU g5.4xlarge#0 with TP=1: min 3 layers (for 50% utilization)
2026-01-30 05:30:11,681 - INFO - GPU g5.4xlarge#1 with TP=1: min 3 layers (for 50% utilization)
2026-01-30 05:30:11,681 - INFO - GPU g5.4xlarge#2 with TP=1: min 3 layers (for 50% utilization)
2026-01-30 05:30:11,681 - INFO - GPU g5.4xlarge#3 with TP=1: min 3 layers (for 50% utilization)
2026-01-30 05:30:11,681 - INFO - Quantized segment sizes (divisors + powers of two): [1, 2, 4, 5, 8, 10, 16, 20, 32, 40, 64, 80]
2026-01-30 05:30:11,681 - INFO -   Using 12 sizes for performance
2026-01-30 05:30:11,681 - INFO - Batch size options: [32]
2026-01-30 05:30:11,681 - INFO - Batch size options: [32]
2026-01-30 05:30:12,940 - INFO - Generated 28571 segments with variable TP and batch size
2026-01-30 05:30:12,941 - INFO -   Batch size options: [32]
2026-01-30 05:30:12,941 - INFO -   Segments per config increased by 1x
2026-01-30 05:30:12,941 - INFO -   Pre-computed throughput for 28571 segments
2026-01-30 05:30:12,941 - INFO -   ✓ Verified 10 random segments - all match!
2026-01-30 05:30:23,049 - INFO - Generated 6258292 connections (before bandwidth filter)
2026-01-30 05:31:21,395 - INFO - Network bandwidth filter (bottom 10%): 6258292 -> 6258292 connections
2026-01-30 05:32:25,395 - INFO - Problem size validation:
2026-01-30 05:32:25,395 - INFO -   - Segments: 28571
2026-01-30 05:32:25,396 - INFO -   - Connections: 6258292
2026-01-30 05:32:25,396 - INFO -   - Binary variables: ~6286863
2026-01-30 05:32:25,396 - WARNING - Large problem (6286863 binary variables)
2026-01-30 05:32:25,396 - INFO - Initialized solver with TP and practical constraints:
2026-01-30 05:32:25,396 - INFO -   - GPU types: 37, Total GPUs: 168
2026-01-30 05:32:25,396 - INFO -   - TP Configuration: {'p4de.24xlarge#0': 8, 'p3dn.24xlarge#0': 8, 'p3dn.24xlarge#1': 8, 'p3dn.24xlarge#2': 8, 'p3dn.24xlarge#3': 8, 'g6e.48xlarge#0': 8, 'g6e.48xlarge#1': 8, 'g6e.48xlarge#2': 8, 'g6e.48xlarge#3': 8, 'g6e.24xlarge#0': 4, 'g6e.24xlarge#1': 4, 'g6e.24xlarge#2': 4, 'g6e.24xlarge#3': 4, 'g6e.12xlarge#0': 2, 'g6e.12xlarge#1': 2, 'g6e.12xlarge#2': 2, 'g6e.12xlarge#3': 2, 'g6e.4xlarge#0': 1, 'g6e.4xlarge#1': 1, 'g6e.4xlarge#2': 1, 'g6e.4xlarge#3': 1, 'g5.48xlarge#0': 8, 'g5.48xlarge#1': 8, 'g5.48xlarge#2': 8, 'g5.48xlarge#3': 8, 'g5.24xlarge#0': 4, 'g5.24xlarge#1': 4, 'g5.24xlarge#2': 4, 'g5.24xlarge#3': 4, 'g5.12xlarge#0': 4, 'g5.12xlarge#1': 4, 'g5.12xlarge#2': 4, 'g5.12xlarge#3': 4, 'g5.4xlarge#0': 1, 'g5.4xlarge#1': 1, 'g5.4xlarge#2': 1, 'g5.4xlarge#3': 1}
2026-01-30 05:32:25,396 - INFO -   - Max pipeline stages: 8
2026-01-30 05:32:25,396 - INFO -   - Min memory utilization: 0.5
2026-01-30 05:32:25,396 - INFO -   - Segment quantization: True
2026-01-30 05:32:25,396 - INFO -   - Model: 80 layers
2026-01-30 05:32:25,396 - INFO -   - Problem size: 28571 segments, 6258292 connections
2026-01-30 05:32:25,397 - ERROR - Eval placement infeasible: INFEASIBLE placement. Context: model_layers=80, phase=aggregated, seq_len=2048, output_len=512, batch=32, pp_stages=4. Reasons: Stage 1 (g6e.48xlarge#0, TP=8, layers 1-20, size=20): underutilized GPU: segment uses 20 layers, but the minimum to reach 50% of GPU memory is 80 layers. Target memory=24.00GB (= 50% of 48.0GB), activation=1.15GB, per_layer=0.26GB ⇒ required_layers=ceil((24.00 - 1.15) / 0.26) = 89 | Stage 2 (g6e.48xlarge#1, TP=8, layers 21-40, size=20): underutilized GPU: segment uses 20 layers, but the minimum to reach 50% of GPU memory is 80 layers. Target memory=24.00GB (= 50% of 48.0GB), activation=1.15GB, per_layer=0.26GB ⇒ required_layers=ceil((24.00 - 1.15) / 0.26) = 89 | Stage 3 (g6e.48xlarge#2, TP=8, layers 41-60, size=20): underutilized GPU: segment uses 20 layers, but the minimum to reach 50% of GPU memory is 80 layers. Target memory=24.00GB (= 50% of 48.0GB), activation=1.15GB, per_layer=0.26GB ⇒ required_layers=ceil((24.00 - 1.15) / 0.26) = 89 | Stage 4 (g6e.48xlarge#3, TP=8, layers 61-80, size=20): underutilized GPU: segment uses 20 layers, but the minimum to reach 50% of GPU memory is 80 layers. Target memory=24.00GB (= 50% of 48.0GB), activation=1.15GB, per_layer=0.26GB ⇒ required_layers=ceil((24.00 - 1.15) / 0.26) = 89
2026-01-30 05:32:26,536 - INFO - Total solver runtime: 135 seconds
