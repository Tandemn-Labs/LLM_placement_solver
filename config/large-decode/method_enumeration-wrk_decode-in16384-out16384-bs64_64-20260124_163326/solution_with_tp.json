{
  "config": {
    "model_name": "llama3-70b-decode",
    "num_decoder_layers": 80,
    "sequence_length": 16384,
    "min_batch_size": 64,
    "max_batch_size": 64,
    "optimal_batch_size": 64,
    "d_model": 8192,
    "d_hidden": 28672,
    "max_pipeline_stages": 8,
    "min_memory_utilization": 0.5
  },
  "solution": {
    "objective_value": 1200.0165649345436,
    "batch_size": 64,
    "throughput_tokens_per_sec": 288.0039755842904,
    "cost_per_hour": 57.25,
    "cost_per_token": 5.521721617041879e-05,
    "total_runtime_hours": 0.9644928588719439,
    "meets_cost_threshold": true,
    "tp_configuration": {
      "p4de.24xlarge#0": 8,
      "p3dn.24xlarge#0": 8,
      "p3dn.24xlarge#1": 8,
      "p3dn.24xlarge#2": 8,
      "p3dn.24xlarge#3": 8,
      "g6e.48xlarge#0": 8,
      "g6e.48xlarge#1": 8,
      "g6e.48xlarge#2": 8,
      "g6e.48xlarge#3": 8,
      "g6e.24xlarge#0": 4,
      "g6e.24xlarge#1": 4,
      "g6e.24xlarge#2": 4,
      "g6e.24xlarge#3": 4,
      "g6e.12xlarge#0": 2,
      "g6e.12xlarge#1": 2,
      "g6e.12xlarge#2": 2,
      "g6e.12xlarge#3": 2,
      "g6e.4xlarge#0": 1,
      "g6e.4xlarge#1": 1,
      "g6e.4xlarge#2": 1,
      "g6e.4xlarge#3": 1,
      "g5.48xlarge#0": 8,
      "g5.48xlarge#1": 8,
      "g5.48xlarge#2": 8,
      "g5.48xlarge#3": 8,
      "g5.24xlarge#0": 4,
      "g5.24xlarge#1": 4,
      "g5.24xlarge#2": 4,
      "g5.24xlarge#3": 4,
      "g5.12xlarge#0": 4,
      "g5.12xlarge#1": 4,
      "g5.12xlarge#2": 4,
      "g5.12xlarge#3": 4,
      "g5.4xlarge#0": 1,
      "g5.4xlarge#1": 1,
      "g5.4xlarge#2": 1,
      "g5.4xlarge#3": 1
    },
    "gpu_assignments": [
      {
        "gpu_type": "p4de.24xlarge#0",
        "partition_id": 14,
        "gpu_ids": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "global_gpu_ids": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "tp_degree": 8,
        "start_layer": 1,
        "end_layer": 64,
        "segment_size": 64,
        "throughput": 1491.5738604620096
      },
      {
        "gpu_type": "g5.48xlarge#2",
        "partition_id": 14,
        "gpu_ids": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ],
        "global_gpu_ids": [
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123
        ],
        "tp_degree": 8,
        "start_layer": 65,
        "end_layer": 80,
        "segment_size": 16,
        "throughput": 1200.0165649345433
      }
    ],
    "network_connections": [],
    "solve_status": 2,
    "num_pipeline_stages": 2
  }
}