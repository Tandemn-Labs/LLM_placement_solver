parameter,value
model_name,qwen2.5-a14b
num_decoder_layers,28
d_model,3584
d_hidden,2560
vocab_size,152064
num_attention_heads,28
layer_weight_memory_gb,2.0
time_limit_seconds,300
optimality_gap,0.01
bytes_per_element,2
enable_segment_quantization,true
max_pipeline_stages,8
min_layers_per_stage,4
min_memory_utilization,0.1
network_bandwidth_percentile_threshold,0.1
optimization_priority,cost_first
max_hourly_cost,999.0
max_cost_per_million_token,100
max_total_cost,999999.0
max_total_runtime_hours,999999.0
throughput_normalization,10000.0
cost_normalization,1.0
total_tokens_to_process,1000000
real_world_efficiency,0.30
micro_batch_size,8
num_kv_heads,4
max_position_embeddings,32768
